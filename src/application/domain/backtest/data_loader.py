# -*- coding: utf-8 -*-
"""
Backtest Data Loader - ë°±í…ŒìŠ¤íŒ… ë°ì´í„° ìˆ˜ì§‘ ë° ì „ì²˜ë¦¬

ê³¼ê±° ì°¨íŠ¸ ë°ì´í„° ìˆ˜ì§‘, ê²€ì¦, ì „ì²˜ë¦¬ë¥¼ ë‹´ë‹¹í•©ë‹ˆë‹¤.
"""

import asyncio
from datetime import datetime, timedelta
import pandas as pd

from sqlalchemy.ext.asyncio import AsyncSession

from src.adapters.database.repositories.ohlcv_repository import OHLCVRepository
from src.application.common.exceptions import BacktestDataError
from src.application.domain.market_data.dto import CandleDTO
from src.application.domain.market_data.service import MarketDataService


class BacktestDataLoader:
    """
    ë°±í…ŒìŠ¤íŒ… ë°ì´í„° ë¡œë”

    ê³¼ê±° ì°¨íŠ¸ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ê³  ë°±í…ŒìŠ¤íŒ…ì— ì í•©í•œ í˜•íƒœë¡œ ì „ì²˜ë¦¬í•©ë‹ˆë‹¤.
    DB ìºì‹±ì„ í†µí•´ ë°˜ë³µ API í˜¸ì¶œì„ ìµœì†Œí™”í•©ë‹ˆë‹¤.
    """

    def __init__(
        self,
        market_data_service: MarketDataService,
        db_session: AsyncSession | None = None,
    ):
        """
        Args:
            market_data_service: ì‹œì„¸ ë°ì´í„° ì„œë¹„ìŠ¤
            db_session: DB ì„¸ì…˜ (ìºì‹± ì‚¬ìš© ì‹œ í•„ìˆ˜)
        """
        self.market_data_service = market_data_service
        self.db_session = db_session
        self.ohlcv_repo = OHLCVRepository(db_session) if db_session else None

    async def load_ohlcv_data(
        self,
        symbol: str,
        start_date: datetime,
        end_date: datetime,
        chunk_days: int = 90,
        use_cache: bool = True,
    ) -> tuple[pd.DataFrame, datetime, datetime]:
        """
        OHLCV ë°ì´í„° ë¡œë“œ (DB ìºì‹œ ìš°ì„ )

        Args:
            symbol: ì¢…ëª©ì½”ë“œ
            start_date: ì‹œì‘ì¼
            end_date: ì¢…ë£Œì¼
            chunk_days: í•œ ë²ˆì— ì¡°íšŒí•  ê¸°ê°„ (ì¼)
            use_cache: ìºì‹œ ì‚¬ìš© ì—¬ë¶€

        Returns:
            tuple:
                - pd.DataFrame: OHLCV ë°ì´í„° (ì»¬ëŸ¼: timestamp, open, high, low, close, volume)
                - datetime: ì‹¤ì œ ë°ì´í„° ì‹œì‘ì¼
                - datetime: ì‹¤ì œ ë°ì´í„° ì¢…ë£Œì¼

        Raises:
            BacktestDataError: ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨
        """
        try:
            # ==================== 1. DB ìºì‹œ í™•ì¸ ====================
            if use_cache and self.ohlcv_repo:
                cached_data = await self._load_from_cache(symbol, start_date, end_date)
                if cached_data is not None:
                    df, actual_start, actual_end = cached_data
                    print(f"âœ… ìºì‹œì—ì„œ ë°ì´í„° ë¡œë“œ: {len(df)}ê±´ (DB)")
                    return df, actual_start, actual_end

            # ==================== 2. APIì—ì„œ ìˆ˜ì§‘ ====================
            all_candles = await self._collect_long_period(
                symbol, start_date, end_date, chunk_days
            )

            if not all_candles:
                raise BacktestDataError(f"No data collected for {symbol}")

            # ==================== 3. DBì— ì €ì¥ ====================
            if use_cache and self.ohlcv_repo:
                await self._save_to_cache(symbol, all_candles)
                await self.db_session.commit()
                print(f"ğŸ’¾ ë°ì´í„° DB ì €ì¥ ì™„ë£Œ: {len(all_candles)}ê±´")

            # ==================== 4. DataFrame ë³€í™˜ ë° ê²€ì¦ ====================
            df = self._candles_to_dataframe(all_candles)
            self._validate_data(df, start_date, end_date)
            df = self._preprocess_data(df)

            actual_start = df["timestamp"].min()
            actual_end = df["timestamp"].max()

            return df, actual_start, actual_end

        except Exception as e:
            if self.db_session:
                await self.db_session.rollback()
            raise BacktestDataError(f"Failed to load OHLCV data for {symbol}: {e}")

    async def _collect_long_period(
        self,
        symbol: str,
        start_date: datetime,
        end_date: datetime,
        chunk_days: int = 90
    ) -> list[CandleDTO]:
        """
        ì¥ê¸°ê°„ ë°ì´í„° ë¶„í•  ìˆ˜ì§‘

        KIS API ì œí•œì„ ê³ ë ¤í•˜ì—¬ ê¸°ê°„ì„ ë‚˜ëˆ ì„œ ìˆ˜ì§‘í•©ë‹ˆë‹¤.

        Args:
            symbol: ì¢…ëª©ì½”ë“œ
            start_date: ì‹œì‘ì¼
            end_date: ì¢…ë£Œì¼
            chunk_days: í•œ ë²ˆì— ì¡°íšŒí•  ê¸°ê°„ (ì¼)

        Returns:
            list[CandleDTO]: ì „ì²´ ê¸°ê°„ ìº”ë“¤ ë°ì´í„°
        """
        candles_by_date: dict[datetime, CandleDTO] = {}
        current_end = end_date
        last_earliest: datetime | None = None

        while current_end >= start_date:
            current_start = max(start_date, current_end - timedelta(days=chunk_days - 1))

            chart_data = await self.market_data_service.get_chart_data(
                symbol=symbol,
                interval="1d",
                start_date=current_start,
                end_date=current_end
            )

            if not chart_data.candles:
                break

            for candle in chart_data.candles:
                if start_date <= candle.timestamp <= end_date:
                    candles_by_date[candle.timestamp] = candle

            earliest_in_chunk = min(c.timestamp for c in chart_data.candles)

            if last_earliest and earliest_in_chunk >= last_earliest:
                # ë” ì´ìƒ ê³¼ê±° ë°ì´í„°ê°€ ë‚´ë ¤ì˜¤ì§€ ì•ŠëŠ” ê²½ìš° (API í•œê³„)
                break

            last_earliest = earliest_in_chunk

            if earliest_in_chunk <= start_date:
                break

            current_end = earliest_in_chunk - timedelta(days=1)
            await asyncio.sleep(0.1)  # Rate limit ëŒ€ì‘

        all_candles = list(candles_by_date.values())
        all_candles.sort(key=lambda x: x.timestamp)
        return all_candles

    def _candles_to_dataframe(self, candles: list[CandleDTO]) -> pd.DataFrame:
        """
        CandleDTO ë¦¬ìŠ¤íŠ¸ë¥¼ DataFrameìœ¼ë¡œ ë³€í™˜

        Args:
            candles: ìº”ë“¤ ë°ì´í„° ë¦¬ìŠ¤íŠ¸

        Returns:
            pd.DataFrame: OHLCV ë°ì´í„°
        """
        data = []
        for candle in candles:
            data.append({
                "timestamp": candle.timestamp,
                "open": float(candle.open),
                "high": float(candle.high),
                "low": float(candle.low),
                "close": float(candle.close),
                "volume": candle.volume,
            })

        df = pd.DataFrame(data)

        # ë‚ ì§œ ì¸ë±ìŠ¤ ì„¤ì •
        df["timestamp"] = pd.to_datetime(df["timestamp"])
        df = df.sort_values("timestamp")
        df = df.reset_index(drop=True)

        return df

    def _validate_data(
        self,
        df: pd.DataFrame,
        start_date: datetime,
        end_date: datetime
    ) -> None:
        """
        ë°ì´í„° ìœ íš¨ì„± ê²€ì¦

        Args:
            df: OHLCV ë°ì´í„°
            start_date: ì˜ˆìƒ ì‹œì‘ì¼
            end_date: ì˜ˆìƒ ì¢…ë£Œì¼

        Raises:
            BacktestDataError: ë°ì´í„° ê²€ì¦ ì‹¤íŒ¨
        """
        # ìµœì†Œ ë°ì´í„° ìˆ˜ í™•ì¸ (ìµœì†Œ 20ì¼ ì´ìƒ)
        if len(df) < 20:
            raise BacktestDataError(
                f"Insufficient data: {len(df)} rows (minimum 20 required)"
            )

        # OHLC ê´€ê³„ ê²€ì¦
        violations = self._validate_ohlc_relationship(df)
        if violations:
            raise BacktestDataError(
                f"OHLC relationship violations found: {len(violations)} rows"
            )

        # ê²°ì¸¡ì¹˜ í™•ì¸
        if df.isnull().any().any():
            raise BacktestDataError("Missing values found in data")

        # ìŒìˆ˜ ê°€ê²© í™•ì¸
        price_columns = ["open", "high", "low", "close"]
        for col in price_columns:
            if (df[col] <= 0).any():
                raise BacktestDataError(f"Negative or zero prices found in {col}")

        # ìŒìˆ˜ ê±°ë˜ëŸ‰ í™•ì¸
        if (df["volume"] < 0).any():
            raise BacktestDataError("Negative volume found")

    def _validate_ohlc_relationship(self, df: pd.DataFrame) -> list[int]:
        """
        OHLC ê´€ê³„ ê²€ì¦

        High >= Open, Close, Low
        Low <= Open, Close, High

        Args:
            df: OHLCV ë°ì´í„°

        Returns:
            list[int]: ìœ„ë°˜ í–‰ ì¸ë±ìŠ¤ ë¦¬ìŠ¤íŠ¸
        """
        violations = []

        for idx, row in df.iterrows():
            # Highê°€ ê°€ì¥ ë†’ì€ì§€
            if row["high"] < row["open"] or row["high"] < row["close"] or row["high"] < row["low"]:
                violations.append(idx)
                continue

            # Lowê°€ ê°€ì¥ ë‚®ì€ì§€
            if row["low"] > row["open"] or row["low"] > row["close"] or row["low"] > row["high"]:
                violations.append(idx)
                continue

        return violations

    def _preprocess_data(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        ë°ì´í„° ì „ì²˜ë¦¬

        - ê²°ì¸¡ì¹˜ ë³´ê°„ (Forward Fill)
        - ì´ìƒì¹˜ ì œê±°
        - ì •ë ¬

        Args:
            df: ì›ë³¸ OHLCV ë°ì´í„°

        Returns:
            pd.DataFrame: ì „ì²˜ë¦¬ëœ ë°ì´í„°
        """
        # ë‚ ì§œìˆœ ì •ë ¬
        df = df.sort_values("timestamp")

        # ê²°ì¸¡ì¹˜ ë³´ê°„ (Forward Fill)
        df = df.ffill()

        # ì¤‘ë³µ ì œê±°
        df = df.drop_duplicates(subset=["timestamp"], keep="first")

        # ì¸ë±ìŠ¤ ë¦¬ì…‹
        df = df.reset_index(drop=True)

        return df

    def validate_missing_dates(
        self,
        df: pd.DataFrame,
        start_date: datetime,
        end_date: datetime
    ) -> dict:
        """
        ê²°ì¸¡ ê±°ë˜ì¼ ê²€ì¦

        Args:
            df: OHLCV ë°ì´í„°
            start_date: ì˜ˆìƒ ì‹œì‘ì¼
            end_date: ì˜ˆìƒ ì¢…ë£Œì¼

        Returns:
            dict: ê²€ì¦ ê²°ê³¼
                - total_expected: ì˜ˆìƒ ê±°ë˜ì¼ ìˆ˜
                - total_actual: ì‹¤ì œ ë°ì´í„° ìˆ˜
                - missing_count: ê²°ì¸¡ì¼ ìˆ˜
                - coverage_rate: ì»¤ë²„ë¦¬ì§€ ë¹„ìœ¨
        """
        # ì‹¤ì œ ë°ì´í„° ë‚ ì§œ ì¶”ì¶œ
        actual_dates = set(df["timestamp"].dt.date)

        # ì˜ˆìƒ ê±°ë˜ì¼ ìƒì„± (ì£¼ë§ ì œì™¸)
        expected_dates = set()
        current = start_date
        while current <= end_date:
            if current.weekday() < 5:  # ì›”~ê¸ˆ
                expected_dates.add(current.date())
            current += timedelta(days=1)

        # ê²°ì¸¡ì¼ í™•ì¸
        missing_dates = expected_dates - actual_dates

        return {
            "total_expected": len(expected_dates),
            "total_actual": len(actual_dates),
            "missing_count": len(missing_dates),
            "coverage_rate": len(actual_dates) / len(expected_dates) if expected_dates else 0.0
        }

    def get_data_summary(self, df: pd.DataFrame) -> dict:
        """
        ë°ì´í„° ìš”ì•½ ì •ë³´

        Args:
            df: OHLCV ë°ì´í„°

        Returns:
            dict: ìš”ì•½ ì •ë³´
        """
        return {
            "total_rows": len(df),
            "start_date": df["timestamp"].min(),
            "end_date": df["timestamp"].max(),
            "price_min": df["low"].min(),
            "price_max": df["high"].max(),
            "avg_volume": int(df["volume"].mean()),
            "total_volume": int(df["volume"].sum()),
        }

    # ==================== DB ìºì‹± í—¬í¼ ë©”ì„œë“œ ====================

    async def _load_from_cache(
        self,
        symbol: str,
        start_date: datetime,
        end_date: datetime,
    ) -> tuple[pd.DataFrame, datetime, datetime] | None:
        """
        DB ìºì‹œì—ì„œ ë°ì´í„° ë¡œë“œ

        Args:
            symbol: ì¢…ëª©ì½”ë“œ
            start_date: ì‹œì‘ì¼
            end_date: ì¢…ë£Œì¼

        Returns:
            tuple | None: (DataFrame, ì‹¤ì œ ì‹œì‘ì¼, ì‹¤ì œ ì¢…ë£Œì¼) ë˜ëŠ” None (ìºì‹œ ë¯¸ìŠ¤)
        """
        if not self.ohlcv_repo:
            return None

        # ë°ì´í„° ê°€ìš©ì„± í™•ì¸
        availability = await self.ohlcv_repo.check_data_availability(
            symbol=symbol,
            start_date=start_date,
            end_date=end_date,
            interval="1d",
        )

        # ì™„ì „í•œ ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ìºì‹œ ë¯¸ìŠ¤
        if not availability["is_complete"]:
            if availability["has_data"]:
                print(f"âš ï¸ ë¶€ë¶„ ìºì‹œ ì¡´ì¬ (ë¯¸ì‚¬ìš©): {availability['count']}ê±´")
            return None

        # DBì—ì„œ DataFrame ë¡œë“œ
        df = await self.ohlcv_repo.get_candles_to_dataframe(
            symbol=symbol,
            start_date=start_date,
            end_date=end_date,
            interval="1d",
        )

        if df.empty:
            return None

        # ë°ì´í„° ê²€ì¦ ë° ì „ì²˜ë¦¬
        self._validate_data(df, start_date, end_date)
        df = self._preprocess_data(df)

        actual_start = df["timestamp"].min()
        actual_end = df["timestamp"].max()

        # íƒ€ì„ì¡´ ì •ê·œí™” (pandas Timestampë¥¼ Python datetimeìœ¼ë¡œ, timezone-naiveë¡œ)
        if hasattr(actual_start, 'to_pydatetime'):
            actual_start = actual_start.to_pydatetime()
        if hasattr(actual_end, 'to_pydatetime'):
            actual_end = actual_end.to_pydatetime()
        if actual_start.tzinfo is not None:
            actual_start = actual_start.replace(tzinfo=None)
        if actual_end.tzinfo is not None:
            actual_end = actual_end.replace(tzinfo=None)

        return df, actual_start, actual_end

    async def _save_to_cache(
        self,
        symbol: str,
        candles: list[CandleDTO],
    ) -> None:
        """
        ìˆ˜ì§‘í•œ ìº”ë“¤ ë°ì´í„°ë¥¼ DBì— ì €ì¥

        Args:
            symbol: ì¢…ëª©ì½”ë“œ
            candles: ìº”ë“¤ ë°ì´í„° ë¦¬ìŠ¤íŠ¸
        """
        if not self.ohlcv_repo or not candles:
            return

        await self.ohlcv_repo.save_candles_bulk(
            symbol=symbol,
            candles=candles,
            interval="1d",
            source="kis",
        )
