# ë°ì´í„° ìˆ˜ì§‘ ë° ê²€ì¦ ê°€ì´ë“œ

## ğŸ“‹ ëª©ì°¨
1. [ê°œìš”](#ê°œìš”)
2. [ë°ì´í„° ìˆ˜ì§‘](#ë°ì´í„°-ìˆ˜ì§‘)
3. [ë°ì´í„° ì €ì¥](#ë°ì´í„°-ì €ì¥)
4. [ë°ì´í„° ê²€ì¦](#ë°ì´í„°-ê²€ì¦)
5. [ì´ìƒ ë°ì´í„° ì²˜ë¦¬](#ì´ìƒ-ë°ì´í„°-ì²˜ë¦¬)
6. [í’ˆì§ˆ ë³´ì¦ ì²´í¬ë¦¬ìŠ¤íŠ¸](#í’ˆì§ˆ-ë³´ì¦-ì²´í¬ë¦¬ìŠ¤íŠ¸)

---

## ê°œìš”

ë°±í…ŒìŠ¤íŒ…ì˜ ì‹ ë¢°ë„ëŠ” **ë°ì´í„° í’ˆì§ˆ**ì— ì§ì ‘ì ìœ¼ë¡œ ì˜ì¡´í•©ë‹ˆë‹¤. ë¶€ì •í™•í•˜ê±°ë‚˜ ë¶ˆì™„ì „í•œ ë°ì´í„°ëŠ” ë°±í…ŒìŠ¤íŒ… ê²°ê³¼ë¥¼ ì™œê³¡ì‹œì¼œ ì‹¤ì „ì—ì„œ ì˜ˆìƒì¹˜ ëª»í•œ ì†ì‹¤ì„ ì´ˆë˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

### ë°ì´í„° í’ˆì§ˆ ëª©í‘œ

| ì§€í‘œ | ëª©í‘œ | ì¤‘ìš”ë„ |
|------|------|--------|
| **ê²°ì¸¡ì¹˜ ë¹„ìœ¨** | 0% | ğŸ”´ Critical |
| **ì´ìƒì¹˜ íƒì§€ìœ¨** | > 99% | ğŸ”´ Critical |
| **ìˆ˜ì •ì£¼ê°€ ì •í™•ë„** | 100% | ğŸ”´ Critical |
| **ê±°ë˜ëŸ‰ ê²€ì¦** | > 99.9% | ğŸŸ¡ Important |
| **ì‹œê°„ ì •í™•ë„** | Â±1ì´ˆ | ğŸŸ¢ Nice-to-have |

---

## ë°ì´í„° ìˆ˜ì§‘

### 1. KIS APIë¥¼ í†µí•œ ì°¨íŠ¸ ë°ì´í„° ìˆ˜ì§‘

#### ì¼ë´‰ ë°ì´í„° ìˆ˜ì§‘

```python
from src.application.domain.market_data.service import MarketDataService
from datetime import datetime, timedelta

async def collect_daily_data(
    service: MarketDataService,
    symbol: str,
    start_date: datetime,
    end_date: datetime
) -> list[CandleDTO]:
    """
    ì¼ë´‰ ë°ì´í„° ìˆ˜ì§‘

    Args:
        service: MarketDataService ì¸ìŠ¤í„´ìŠ¤
        symbol: ì¢…ëª©ì½”ë“œ (ì˜ˆ: "005930")
        start_date: ì‹œì‘ì¼
        end_date: ì¢…ë£Œì¼

    Returns:
        list[CandleDTO]: ìº”ë“¤ ë°ì´í„° ë¦¬ìŠ¤íŠ¸
    """
    chart_data = await service.get_chart_data(
        symbol=symbol,
        interval="1d",
        start_date=start_date,
        end_date=end_date
    )

    return chart_data.candles
```

#### ìˆ˜ì •ì£¼ê°€ vs ì›ì£¼ê°€

KIS APIëŠ” ë‘ ê°€ì§€ ê°€ê²© ì˜µì…˜ì„ ì œê³µí•©ë‹ˆë‹¤:

```python
# MarketDataService ë‚´ë¶€ (src/application/domain/market_data/service.py:218)
params = {
    "FID_ORG_ADJ_PRC": "0",  # 0: ìˆ˜ì •ì£¼ê°€, 1: ì›ì£¼ê°€
}
```

| ì˜µì…˜ | ì„¤ëª… | ë°±í…ŒìŠ¤íŒ… ê¶Œì¥ |
|------|------|--------------|
| **ìˆ˜ì •ì£¼ê°€** | ì£¼ì‹ ë¶„í• , ë³‘í•©, ë°°ë‹¹ ë“± ë°˜ì˜í•œ ì¡°ì •ê°€ê²© | âœ… **ê¶Œì¥** |
| **ì›ì£¼ê°€** | ì‹¤ì œ ê±°ë˜ëœ ê°€ê²© (ì¡°ì • ì „) | âŒ ë¹„ê¶Œì¥ |

**âš ï¸ ì¤‘ìš”**: ë°±í…ŒìŠ¤íŒ…ì—ëŠ” ë°˜ë“œì‹œ **ìˆ˜ì •ì£¼ê°€(0)**ë¥¼ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤. ì›ì£¼ê°€ë¥¼ ì‚¬ìš©í•˜ë©´ ì£¼ì‹ ë¶„í• /ë³‘í•© ì‹œ ê°€ê²© ì™œê³¡ì´ ë°œìƒí•©ë‹ˆë‹¤.

#### API ì œí•œì‚¬í•­

| í•­ëª© | ì œí•œ | ëŒ€ì‘ ë°©ì•ˆ |
|------|------|----------|
| ìš”ì²­ íšŸìˆ˜ | ì´ˆë‹¹ 20íšŒ | Rate Limiter êµ¬í˜„ |
| ìµœëŒ€ ì¡°íšŒ ê¸°ê°„ | ì¢…ëª©ë³„ ìƒì´ | ì—¬ëŸ¬ ë²ˆ ë‚˜ëˆ ì„œ í˜¸ì¶œ |
| íƒ€ì„ì•„ì›ƒ | 30ì´ˆ | Retry ë¡œì§ êµ¬í˜„ |

```python
import asyncio
from typing import AsyncGenerator

async def collect_with_rate_limit(
    service: MarketDataService,
    symbols: list[str],
    start_date: datetime,
    end_date: datetime,
    max_requests_per_second: int = 20
) -> AsyncGenerator[tuple[str, list[CandleDTO]], None]:
    """
    Rate Limitì„ ê³ ë ¤í•œ ë°ì´í„° ìˆ˜ì§‘

    Args:
        service: MarketDataService ì¸ìŠ¤í„´ìŠ¤
        symbols: ì¢…ëª© ë¦¬ìŠ¤íŠ¸
        start_date: ì‹œì‘ì¼
        end_date: ì¢…ë£Œì¼
        max_requests_per_second: ì´ˆë‹¹ ìµœëŒ€ ìš”ì²­ ìˆ˜

    Yields:
        tuple[ì¢…ëª©ì½”ë“œ, ìº”ë“¤ ë°ì´í„°]
    """
    delay = 1.0 / max_requests_per_second

    for symbol in symbols:
        try:
            data = await collect_daily_data(service, symbol, start_date, end_date)
            yield (symbol, data)

            await asyncio.sleep(delay)  # Rate Limit ëŒ€ì‘

        except Exception as e:
            print(f"âš ï¸ {symbol} ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
            continue
```

### 2. ëŒ€ëŸ‰ ë°ì´í„° ìˆ˜ì§‘ ì „ëµ

#### ê¸°ê°„ ë¶„í•  ìˆ˜ì§‘

```python
from datetime import timedelta

async def collect_long_period(
    service: MarketDataService,
    symbol: str,
    start_date: datetime,
    end_date: datetime,
    chunk_days: int = 365  # 1ë…„ì”© ë¶„í• 
) -> list[CandleDTO]:
    """
    ì¥ê¸°ê°„ ë°ì´í„°ë¥¼ ê¸°ê°„ë³„ë¡œ ë‚˜ëˆ ì„œ ìˆ˜ì§‘

    Args:
        service: MarketDataService ì¸ìŠ¤í„´ìŠ¤
        symbol: ì¢…ëª©ì½”ë“œ
        start_date: ì‹œì‘ì¼
        end_date: ì¢…ë£Œì¼
        chunk_days: í•œ ë²ˆì— ì¡°íšŒí•  ê¸°ê°„ (ì¼)

    Returns:
        list[CandleDTO]: ì „ì²´ ê¸°ê°„ ìº”ë“¤ ë°ì´í„°
    """
    all_candles = []
    current_date = start_date

    while current_date < end_date:
        chunk_end = min(current_date + timedelta(days=chunk_days), end_date)

        print(f"ğŸ“¥ ìˆ˜ì§‘ ì¤‘: {symbol} ({current_date.date()} ~ {chunk_end.date()})")

        candles = await collect_daily_data(
            service, symbol, current_date, chunk_end
        )
        all_candles.extend(candles)

        current_date = chunk_end
        await asyncio.sleep(0.1)  # ì•ˆì •ì„±ì„ ìœ„í•œ ì§§ì€ ëŒ€ê¸°

    # ë‚ ì§œìˆœ ì •ë ¬ (ì˜¤ë˜ëœ ê²ƒë¶€í„°)
    all_candles.sort(key=lambda x: x.timestamp)

    return all_candles
```

---

## ë°ì´í„° ì €ì¥

### 1. PostgreSQL ì €ì¥ (ê¶Œì¥)

#### í…Œì´ë¸” ì„¤ê³„

```sql
-- ì°¨íŠ¸ ë°ì´í„° í…Œì´ë¸”
CREATE TABLE chart_data (
    id SERIAL PRIMARY KEY,
    symbol VARCHAR(20) NOT NULL,
    date DATE NOT NULL,
    open DECIMAL(18, 2) NOT NULL,
    high DECIMAL(18, 2) NOT NULL,
    low DECIMAL(18, 2) NOT NULL,
    close DECIMAL(18, 2) NOT NULL,
    volume BIGINT NOT NULL,
    adjusted BOOLEAN DEFAULT TRUE,  -- ìˆ˜ì •ì£¼ê°€ ì—¬ë¶€
    created_at TIMESTAMP DEFAULT NOW(),
    updated_at TIMESTAMP DEFAULT NOW(),

    UNIQUE(symbol, date)  -- ì¤‘ë³µ ë°©ì§€
);

CREATE INDEX idx_chart_symbol_date ON chart_data(symbol, date);
CREATE INDEX idx_chart_date ON chart_data(date);
```

#### SQLAlchemy ëª¨ë¸

```python
# src/adapters/database/models/chart_data.py
from sqlalchemy import Column, Integer, String, Date, Numeric, BigInteger, Boolean, DateTime, UniqueConstraint
from src.adapters.database.models.base import Base
from datetime import datetime

class ChartData(Base):
    """ì°¨íŠ¸ ë°ì´í„° ëª¨ë¸"""

    __tablename__ = "chart_data"

    id = Column(Integer, primary_key=True, autoincrement=True)
    symbol = Column(String(20), nullable=False, index=True)
    date = Column(Date, nullable=False, index=True)
    open = Column(Numeric(18, 2), nullable=False)
    high = Column(Numeric(18, 2), nullable=False)
    low = Column(Numeric(18, 2), nullable=False)
    close = Column(Numeric(18, 2), nullable=False)
    volume = Column(BigInteger, nullable=False)
    adjusted = Column(Boolean, default=True, comment="ìˆ˜ì •ì£¼ê°€ ì—¬ë¶€")
    created_at = Column(DateTime, default=datetime.now)
    updated_at = Column(DateTime, default=datetime.now, onupdate=datetime.now)

    __table_args__ = (
        UniqueConstraint('symbol', 'date', name='uq_symbol_date'),
    )
```

#### ë°ì´í„° ì €ì¥ í•¨ìˆ˜

```python
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy.dialects.postgresql import insert

async def save_chart_data(
    session: AsyncSession,
    symbol: str,
    candles: list[CandleDTO]
) -> int:
    """
    ì°¨íŠ¸ ë°ì´í„° ì €ì¥ (Upsert)

    Args:
        session: SQLAlchemy ì„¸ì…˜
        symbol: ì¢…ëª©ì½”ë“œ
        candles: ìº”ë“¤ ë°ì´í„° ë¦¬ìŠ¤íŠ¸

    Returns:
        int: ì €ì¥ëœ ë ˆì½”ë“œ ìˆ˜
    """
    records = [
        {
            "symbol": symbol,
            "date": candle.timestamp.date(),
            "open": float(candle.open),
            "high": float(candle.high),
            "low": float(candle.low),
            "close": float(candle.close),
            "volume": candle.volume,
            "adjusted": True,
        }
        for candle in candles
    ]

    # Upsert (ì¤‘ë³µ ì‹œ ì—…ë°ì´íŠ¸)
    stmt = insert(ChartData).values(records)
    stmt = stmt.on_conflict_do_update(
        index_elements=['symbol', 'date'],
        set_={
            "open": stmt.excluded.open,
            "high": stmt.excluded.high,
            "low": stmt.excluded.low,
            "close": stmt.excluded.close,
            "volume": stmt.excluded.volume,
            "updated_at": datetime.now(),
        }
    )

    result = await session.execute(stmt)
    await session.commit()

    return result.rowcount
```

### 2. CSV íŒŒì¼ ì €ì¥ (ë°±ì—…/ê³µìœ ìš©)

```python
import pandas as pd
from pathlib import Path

def save_to_csv(
    symbol: str,
    candles: list[CandleDTO],
    output_dir: str = "./data/backtest"
) -> str:
    """
    CSV íŒŒì¼ë¡œ ì €ì¥

    Args:
        symbol: ì¢…ëª©ì½”ë“œ
        candles: ìº”ë“¤ ë°ì´í„°
        output_dir: ì¶œë ¥ ë””ë ‰í† ë¦¬

    Returns:
        str: ì €ì¥ëœ íŒŒì¼ ê²½ë¡œ
    """
    # DataFrame ìƒì„±
    df = pd.DataFrame([
        {
            "date": candle.timestamp.date(),
            "open": float(candle.open),
            "high": float(candle.high),
            "low": float(candle.low),
            "close": float(candle.close),
            "volume": candle.volume,
        }
        for candle in candles
    ])

    # ë‚ ì§œìˆœ ì •ë ¬
    df = df.sort_values("date")

    # ë””ë ‰í† ë¦¬ ìƒì„±
    Path(output_dir).mkdir(parents=True, exist_ok=True)

    # íŒŒì¼ ì €ì¥
    file_path = f"{output_dir}/{symbol}.csv"
    df.to_csv(file_path, index=False, encoding="utf-8-sig")

    print(f"âœ… CSV ì €ì¥ ì™„ë£Œ: {file_path} ({len(df)}ê±´)")
    return file_path
```

### 3. Redis ìºì‹±

```python
from src.adapters.cache.redis_client import RedisClient
import json

async def cache_chart_data(
    redis_client: RedisClient,
    symbol: str,
    candles: list[CandleDTO],
    ttl: int = 86400  # 1ì¼
) -> None:
    """
    ì°¨íŠ¸ ë°ì´í„° Redis ìºì‹±

    Args:
        redis_client: Redis í´ë¼ì´ì–¸íŠ¸
        symbol: ì¢…ëª©ì½”ë“œ
        candles: ìº”ë“¤ ë°ì´í„°
        ttl: TTL (ì´ˆ)
    """
    cache_key = f"chart_data:{symbol}"

    data = [candle.model_dump(mode='json') for candle in candles]

    await redis_client.set(cache_key, json.dumps(data), ttl=ttl)
```

---

## ë°ì´í„° ê²€ì¦

### 1. ê²°ì¸¡ì¹˜ ê²€ì¦

#### ê±°ë˜ì¼ ê²°ì¸¡ì¹˜ í™•ì¸

```python
from datetime import datetime, timedelta
import pandas as pd

def validate_missing_dates(
    candles: list[CandleDTO],
    start_date: datetime,
    end_date: datetime
) -> dict[str, any]:
    """
    ê²°ì¸¡ ê±°ë˜ì¼ ê²€ì¦

    Args:
        candles: ìº”ë“¤ ë°ì´í„°
        start_date: ì˜ˆìƒ ì‹œì‘ì¼
        end_date: ì˜ˆìƒ ì¢…ë£Œì¼

    Returns:
        dict: ê²€ì¦ ê²°ê³¼
    """
    # ì‹¤ì œ ë°ì´í„° ë‚ ì§œ ì¶”ì¶œ
    actual_dates = {candle.timestamp.date() for candle in candles}

    # ì˜ˆìƒ ê±°ë˜ì¼ ìƒì„± (ì£¼ë§ ì œì™¸)
    expected_dates = set()
    current = start_date
    while current <= end_date:
        if current.weekday() < 5:  # ì›”~ê¸ˆ
            expected_dates.add(current.date())
        current += timedelta(days=1)

    # ê²°ì¸¡ì¼ í™•ì¸
    missing_dates = sorted(expected_dates - actual_dates)

    return {
        "total_expected": len(expected_dates),
        "total_actual": len(actual_dates),
        "missing_count": len(missing_dates),
        "missing_dates": missing_dates[:10],  # ìµœëŒ€ 10ê°œë§Œ
        "coverage_rate": len(actual_dates) / len(expected_dates) if expected_dates else 0.0
    }
```

#### ê²°ì¸¡ì¹˜ ë³´ê°„

```python
def fill_missing_data(candles: list[CandleDTO]) -> list[CandleDTO]:
    """
    ê²°ì¸¡ì¹˜ ë³´ê°„ (Forward Fill)

    Args:
        candles: ìº”ë“¤ ë°ì´í„°

    Returns:
        list[CandleDTO]: ë³´ê°„ëœ ìº”ë“¤ ë°ì´í„°
    """
    df = pd.DataFrame([
        {
            "timestamp": c.timestamp,
            "open": float(c.open),
            "high": float(c.high),
            "low": float(c.low),
            "close": float(c.close),
            "volume": c.volume,
        }
        for c in candles
    ])

    # ë‚ ì§œ ì¸ë±ìŠ¤ ì„¤ì •
    df = df.set_index("timestamp")
    df = df.sort_index()

    # ê²°ì¸¡ì¹˜ Forward Fill (ì´ì „ ê°’ìœ¼ë¡œ ì±„ìš°ê¸°)
    df = df.asfreq('D', method='ffill')

    # CandleDTOë¡œ ë³€í™˜
    filled_candles = [
        CandleDTO(
            timestamp=idx.to_pydatetime(),
            open=Decimal(str(row["open"])),
            high=Decimal(str(row["high"])),
            low=Decimal(str(row["low"])),
            close=Decimal(str(row["close"])),
            volume=int(row["volume"]),
        )
        for idx, row in df.iterrows()
    ]

    return filled_candles
```

### 2. ì´ìƒì¹˜ ê²€ì¦

#### ê°€ê²© ì´ìƒì¹˜ íƒì§€

```python
def detect_price_outliers(candles: list[CandleDTO], z_threshold: float = 5.0) -> list[dict]:
    """
    ê°€ê²© ì´ìƒì¹˜ íƒì§€ (Z-Score ë°©ì‹)

    Args:
        candles: ìº”ë“¤ ë°ì´í„°
        z_threshold: Z-Score ì„ê³„ê°’ (ê¸°ë³¸ 5.0)

    Returns:
        list[dict]: ì´ìƒì¹˜ ë¦¬ìŠ¤íŠ¸
    """
    df = pd.DataFrame([
        {
            "date": c.timestamp.date(),
            "close": float(c.close),
            "daily_return": None,
        }
        for c in candles
    ])

    # ì¼ì¼ ìˆ˜ìµë¥  ê³„ì‚°
    df["daily_return"] = df["close"].pct_change()

    # Z-Score ê³„ì‚°
    mean_return = df["daily_return"].mean()
    std_return = df["daily_return"].std()
    df["z_score"] = (df["daily_return"] - mean_return) / std_return

    # ì´ìƒì¹˜ í•„í„°ë§
    outliers = df[abs(df["z_score"]) > z_threshold]

    return outliers.to_dict('records')
```

#### OHLC ê´€ê³„ ê²€ì¦

```python
def validate_ohlc_relationship(candles: list[CandleDTO]) -> list[dict]:
    """
    OHLC ê´€ê³„ ê²€ì¦ (High >= Open, Close >= Low)

    Args:
        candles: ìº”ë“¤ ë°ì´í„°

    Returns:
        list[dict]: ìœ„ë°˜ ì‚¬ë¡€
    """
    violations = []

    for candle in candles:
        issues = []

        # Highê°€ ê°€ì¥ ë†’ì€ì§€
        if candle.high < candle.open or candle.high < candle.close:
            issues.append("High < Open or Close")

        # Lowê°€ ê°€ì¥ ë‚®ì€ì§€
        if candle.low > candle.open or candle.low > candle.close:
            issues.append("Low > Open or Close")

        # High >= Low
        if candle.high < candle.low:
            issues.append("High < Low")

        if issues:
            violations.append({
                "date": candle.timestamp.date(),
                "open": float(candle.open),
                "high": float(candle.high),
                "low": float(candle.low),
                "close": float(candle.close),
                "issues": issues,
            })

    return violations
```

### 3. ê±°ë˜ëŸ‰ ê²€ì¦

```python
def validate_volume(candles: list[CandleDTO]) -> dict[str, any]:
    """
    ê±°ë˜ëŸ‰ ê²€ì¦

    Args:
        candles: ìº”ë“¤ ë°ì´í„°

    Returns:
        dict: ê²€ì¦ ê²°ê³¼
    """
    volumes = [c.volume for c in candles]

    zero_volume_count = sum(1 for v in volumes if v == 0)
    negative_volume_count = sum(1 for v in volumes if v < 0)

    return {
        "total_count": len(volumes),
        "zero_volume_count": zero_volume_count,
        "negative_volume_count": negative_volume_count,
        "zero_volume_ratio": zero_volume_count / len(volumes) if volumes else 0.0,
        "avg_volume": sum(volumes) / len(volumes) if volumes else 0,
        "max_volume": max(volumes) if volumes else 0,
        "min_volume": min(volumes) if volumes else 0,
    }
```

---

## ì´ìƒ ë°ì´í„° ì²˜ë¦¬

### 1. íœ´ì¥ì¼ ì²˜ë¦¬

#### KRX íœ´ì¥ì¼ API í™œìš©

```python
async def check_holiday(service: MarketDataService, date: datetime) -> bool:
    """
    íœ´ì¥ì¼ ì—¬ë¶€ í™•ì¸

    Args:
        service: MarketDataService
        date: í™•ì¸í•  ë‚ ì§œ

    Returns:
        bool: íœ´ì¥ì¼ì´ë©´ True
    """
    # KIS APIì˜ íœ´ì¥ì¼ ì¡°íšŒ TR í™œìš©
    # TR_ID: CTCA0903R (êµ­ë‚´íœ´ì¥ì¼ì¡°íšŒ)
    # ì‹¤ì œ êµ¬í˜„ì€ KIS API ë¬¸ì„œ ì°¸ì¡°

    # ì£¼ë§ì€ í•­ìƒ íœ´ì¥
    if date.weekday() >= 5:
        return True

    # ê³µíœ´ì¼ í™•ì¸ (API í˜¸ì¶œ)
    # ... API í˜¸ì¶œ ë¡œì§

    return False
```

#### íœ´ì¥ì¼ ì œì™¸ ì „ì²˜ë¦¬

```python
async def filter_holidays(
    candles: list[CandleDTO],
    service: MarketDataService
) -> list[CandleDTO]:
    """
    íœ´ì¥ì¼ ë°ì´í„° ì œê±°

    Args:
        candles: ìº”ë“¤ ë°ì´í„°
        service: MarketDataService

    Returns:
        list[CandleDTO]: íœ´ì¥ì¼ ì œê±°ëœ ìº”ë“¤ ë°ì´í„°
    """
    filtered = []

    for candle in candles:
        is_holiday = await check_holiday(service, candle.timestamp)

        if not is_holiday:
            filtered.append(candle)

    return filtered
```

### 2. ì£¼ì‹ ë¶„í• /ë³‘í•© ì¡°ì •

**âš ï¸ ì¤‘ìš”**: KIS APIì—ì„œ ìˆ˜ì •ì£¼ê°€(`FID_ORG_ADJ_PRC="0"`)ë¥¼ ì‚¬ìš©í•˜ë©´ ìë™ìœ¼ë¡œ ì¡°ì •ë©ë‹ˆë‹¤.

#### ìˆ˜ë™ ì¡°ì •ì´ í•„ìš”í•œ ê²½ìš°

```python
def adjust_for_split(
    candles: list[CandleDTO],
    split_date: datetime,
    split_ratio: float  # ì˜ˆ: 1:5 ë¶„í• ì´ë©´ 5.0
) -> list[CandleDTO]:
    """
    ì£¼ì‹ ë¶„í•  ìˆ˜ë™ ì¡°ì •

    Args:
        candles: ìº”ë“¤ ë°ì´í„°
        split_date: ë¶„í•  ê¸°ì¤€ì¼
        split_ratio: ë¶„í•  ë¹„ìœ¨

    Returns:
        list[CandleDTO]: ì¡°ì •ëœ ìº”ë“¤ ë°ì´í„°
    """
    adjusted = []

    for candle in candles:
        if candle.timestamp < split_date:
            # ë¶„í•  ì´ì „ ë°ì´í„°ëŠ” ê°€ê²©ì„ ë‚˜ëˆ„ê³  ê±°ë˜ëŸ‰ì„ ê³±í•¨
            adjusted.append(
                CandleDTO(
                    timestamp=candle.timestamp,
                    open=candle.open / Decimal(str(split_ratio)),
                    high=candle.high / Decimal(str(split_ratio)),
                    low=candle.low / Decimal(str(split_ratio)),
                    close=candle.close / Decimal(str(split_ratio)),
                    volume=int(candle.volume * split_ratio),
                )
            )
        else:
            # ë¶„í•  ì´í›„ëŠ” ê·¸ëŒ€ë¡œ
            adjusted.append(candle)

    return adjusted
```

### 3. ì´ìƒì¹˜ ì²˜ë¦¬ ì „ëµ

| ì´ìƒì¹˜ ìœ í˜• | ì²˜ë¦¬ ë°©ë²• | êµ¬í˜„ |
|-----------|----------|------|
| **OHLC ê´€ê³„ ìœ„ë°˜** | ë°ì´í„° ì œê±° ë˜ëŠ” ë³´ì • | í•´ë‹¹ ë‚ ì§œ ì œê±° |
| **ê±°ë˜ëŸ‰ 0** | ì „ì¼ ë°ì´í„°ë¡œ ëŒ€ì²´ | Forward Fill |
| **ê¸‰ê²©í•œ ê°€ê²© ë³€ë™** | ë‰´ìŠ¤ í™•ì¸ í›„ íŒë‹¨ | ìˆ˜ë™ ê²€í†  |
| **ê²°ì¸¡ì¼** | ì „ì¼ ì¢…ê°€ë¡œ ì±„ìš°ê¸° | Forward Fill |

```python
def clean_outliers(candles: list[CandleDTO]) -> list[CandleDTO]:
    """
    ì´ìƒì¹˜ ì •ì œ

    Args:
        candles: ì›ë³¸ ìº”ë“¤ ë°ì´í„°

    Returns:
        list[CandleDTO]: ì •ì œëœ ìº”ë“¤ ë°ì´í„°
    """
    # 1. OHLC ê´€ê³„ ê²€ì¦
    violations = validate_ohlc_relationship(candles)
    violation_dates = {v["date"] for v in violations}

    # 2. ìœ„ë°˜ ë°ì´í„° ì œê±°
    cleaned = [c for c in candles if c.timestamp.date() not in violation_dates]

    # 3. ê±°ë˜ëŸ‰ 0ì¸ ê²½ìš° ì „ì¼ ë°ì´í„°ë¡œ ëŒ€ì²´
    cleaned = fill_missing_data(cleaned)

    print(f"âœ… ì •ì œ ì™„ë£Œ: ì›ë³¸ {len(candles)}ê±´ â†’ ì •ì œ {len(cleaned)}ê±´ (ì œê±° {len(violation_dates)}ê±´)")

    return cleaned
```

---

## í’ˆì§ˆ ë³´ì¦ ì²´í¬ë¦¬ìŠ¤íŠ¸

### ìˆ˜ì§‘ ì „ ì²´í¬ë¦¬ìŠ¤íŠ¸

- [ ] KIS API í† í° ìœ íš¨ì„± í™•ì¸
- [ ] ìˆ˜ì§‘ ê¸°ê°„ ì„¤ì • (ìµœì†Œ 1ë…„, ê¶Œì¥ 3-5ë…„)
- [ ] ì¢…ëª© ë¦¬ìŠ¤íŠ¸ ê²€ì¦ (ìƒì¥íì§€ ì¢…ëª© ì œì™¸)
- [ ] Rate Limit ì„¤ì • (ì´ˆë‹¹ 20íšŒ)
- [ ] ì €ì¥ ê³µê°„ í™•ì¸ (ì¢…ëª©ë‹¹ ì•½ 1MB)

### ìˆ˜ì§‘ í›„ ì²´í¬ë¦¬ìŠ¤íŠ¸

- [ ] **ê²°ì¸¡ì¹˜ 0% ë‹¬ì„±**
  ```python
  result = validate_missing_dates(candles, start_date, end_date)
  assert result["missing_count"] == 0, f"ê²°ì¸¡ì¼ {result['missing_count']}ê±´ ë°œê²¬"
  ```

- [ ] **OHLC ê´€ê³„ ê²€ì¦ í†µê³¼**
  ```python
  violations = validate_ohlc_relationship(candles)
  assert len(violations) == 0, f"OHLC ìœ„ë°˜ {len(violations)}ê±´"
  ```

- [ ] **ê±°ë˜ëŸ‰ ê²€ì¦ í†µê³¼**
  ```python
  vol_result = validate_volume(candles)
  assert vol_result["negative_volume_count"] == 0, "ìŒìˆ˜ ê±°ë˜ëŸ‰ ë°œê²¬"
  ```

- [ ] **ê°€ê²© ì´ìƒì¹˜ í™•ì¸**
  ```python
  outliers = detect_price_outliers(candles)
  if outliers:
      print(f"âš ï¸ ì´ìƒì¹˜ {len(outliers)}ê±´ í™•ì¸ í•„ìš”")
  ```

- [ ] **ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ í™•ì¸**
  ```python
  saved_count = await save_chart_data(session, symbol, candles)
  assert saved_count == len(candles), "ì €ì¥ ì‹¤íŒ¨"
  ```

### ë°±í…ŒìŠ¤íŒ… ì „ ì²´í¬ë¦¬ìŠ¤íŠ¸

- [ ] ìˆ˜ì •ì£¼ê°€ ì‚¬ìš© í™•ì¸
- [ ] ìƒì¡´ í¸í–¥ ê³ ë ¤ (ìƒì¥íì§€ ì¢…ëª© í¬í•¨ ì—¬ë¶€)
- [ ] ì¶©ë¶„í•œ ë°ì´í„° ê¸°ê°„ (ìµœì†Œ 20ì¼ ì´ìƒ)
- [ ] íœ´ì¥ì¼ ì œê±° ì™„ë£Œ
- [ ] ë°ì´í„° ì •ë ¬ (ë‚ ì§œ ì˜¤ë¦„ì°¨ìˆœ)

---

## ìë™í™” ìŠ¤í¬ë¦½íŠ¸

### ì „ì²´ íŒŒì´í”„ë¼ì¸

```python
async def data_collection_pipeline(
    symbols: list[str],
    start_date: datetime,
    end_date: datetime,
    service: MarketDataService,
    session: AsyncSession
) -> dict[str, any]:
    """
    ë°ì´í„° ìˆ˜ì§‘ ì „ì²´ íŒŒì´í”„ë¼ì¸

    Args:
        symbols: ì¢…ëª© ë¦¬ìŠ¤íŠ¸
        start_date: ì‹œì‘ì¼
        end_date: ì¢…ë£Œì¼
        service: MarketDataService
        session: SQLAlchemy ì„¸ì…˜

    Returns:
        dict: ìˆ˜ì§‘ ê²°ê³¼ ìš”ì•½
    """
    results = {
        "success": [],
        "failed": [],
        "total_records": 0,
    }

    for symbol in symbols:
        try:
            print(f"\nğŸ“Š ì²˜ë¦¬ ì¤‘: {symbol}")

            # 1. ë°ì´í„° ìˆ˜ì§‘
            candles = await collect_long_period(symbol, start_date, end_date)
            print(f"  âœ… ìˆ˜ì§‘: {len(candles)}ê±´")

            # 2. ë°ì´í„° ê²€ì¦
            missing_result = validate_missing_dates(candles, start_date, end_date)
            print(f"  âœ… ì»¤ë²„ë¦¬ì§€: {missing_result['coverage_rate']*100:.1f}%")

            ohlc_violations = validate_ohlc_relationship(candles)
            if ohlc_violations:
                print(f"  âš ï¸ OHLC ìœ„ë°˜: {len(ohlc_violations)}ê±´")

            # 3. ì´ìƒì¹˜ ì •ì œ
            cleaned = clean_outliers(candles)

            # 4. ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥
            saved_count = await save_chart_data(session, symbol, cleaned)
            print(f"  âœ… ì €ì¥: {saved_count}ê±´")

            # 5. CSV ë°±ì—…
            save_to_csv(symbol, cleaned)

            results["success"].append(symbol)
            results["total_records"] += saved_count

        except Exception as e:
            print(f"  âŒ ì‹¤íŒ¨: {e}")
            results["failed"].append({"symbol": symbol, "error": str(e)})

    print(f"\n{'='*60}")
    print(f"ğŸ‰ ìˆ˜ì§‘ ì™„ë£Œ: ì„±ê³µ {len(results['success'])}ê°œ, ì‹¤íŒ¨ {len(results['failed'])}ê°œ")
    print(f"ğŸ“Š ì´ ë ˆì½”ë“œ: {results['total_records']:,}ê±´")

    return results
```

### ì‚¬ìš© ì˜ˆì œ

```python
from datetime import datetime
import asyncio

async def main():
    """ë©”ì¸ ì‹¤í–‰"""
    # ì´ˆê¸°í™”
    service = MarketDataService(kis_client, redis_client)

    # ì¢…ëª© ë¦¬ìŠ¤íŠ¸
    symbols = [
        "005930",  # ì‚¼ì„±ì „ì
        "000660",  # SKí•˜ì´ë‹‰ìŠ¤
        "035420",  # NAVER
    ]

    # ê¸°ê°„ ì„¤ì •
    start_date = datetime(2020, 1, 1)
    end_date = datetime(2024, 12, 31)

    # íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
    results = await data_collection_pipeline(
        symbols, start_date, end_date, service, session
    )

    # ê²°ê³¼ ì¶œë ¥
    if results["failed"]:
        print(f"\nâš ï¸ ì‹¤íŒ¨í•œ ì¢…ëª©:")
        for item in results["failed"]:
            print(f"  - {item['symbol']}: {item['error']}")

if __name__ == "__main__":
    asyncio.run(main())
```

---

## ë¬¸ì˜ ë° ì§€ì›

ë°ì´í„° ìˆ˜ì§‘/ê²€ì¦ ê´€ë ¨ ë¬¸ì˜ëŠ” GitHub Issuesë¡œ ë“±ë¡í•´ì£¼ì„¸ìš”.

- GitHub: [í”„ë¡œì íŠ¸ ì´ìŠˆ](https://github.com/isinthesky/envelope-stock-fastapi/issues)

---

**ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸**: 2025-10-22
**ë¬¸ì„œ ë²„ì „**: 1.0
